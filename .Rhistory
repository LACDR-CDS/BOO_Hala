countData_sample_colnames <- colnames(countData)
# 2. Get sample identifiers from the 'sample_ID' column of metaData.
metaData_sample_ids <- metaData$sample_ID
are_identical_and_in_order <- all(countData_sample_colnames == metaData_sample_ids)
print (are_identical_and_in_order)
# Yes, there are identical
# Calculate new library sizes from the current (probe-QC'd) countData
recalculated_library_sizes <- colSums(countData)
View(countData)
View(cpmData)
View(metaData)
View(cpmData)
View(cpmData)
View(countData)
View(countData)
metaData
sample_ID
View(metaData)
View(metaData)
metaData
#1. Get sample identifiers from the column names of countData.
countData_sample_colnames <- colnames(countData)
# 2. Get sample identifiers from the 'sample_ID' column of metaData.
metaData_sample_ids <- metaData$sample_ID
are_identical_and_in_order <- all(countData_sample_colnames == metaData_sample_ids)
print (are_identical_and_in_order)
# Yes, there are identical
colnames
# Load packages
library(tidyverse)
library(ggrepel) # For repelling text labels in ggplot
#1. Get sample identifiers from the column names of countData.
countData_sample_colnames <- colnames(countData)
# 2. Get sample identifiers from the 'sample_ID' column of metaData.
metaData_sample_ids <- metaData$sample_ID
are_identical_and_in_order <- all(countData_sample_colnames == metaData_sample_ids)
print (are_identical_and_in_order)
# Yes, there are identical
countData_sample_colnames
View(countData)
metaData_sample_ids
metaData <- metaData %>% column_to_rownames(var = "X")
countData <- countData %>% column_to_rownames(var = "X")
#1. Get sample identifiers from the column names of countData.
countData_sample_colnames <- colnames(countData)
# 2. Get sample identifiers from the 'sample_ID' column of metaData.
metaData_sample_ids <- metaData$sample_ID
are_identical_and_in_order <- all(countData_sample_colnames == metaData_sample_ids)
print (are_identical_and_in_order)
# Yes, there are identical
# clean
rm(list = ls())
count_path <- file.path("output/count_store.csv")
cpm_path <- file.path("output/cpm_store2.csv")
metadata_path <- file.path("output/processed_metaData.RData")
output_dir_script3 <- "output"
if (!dir.exists(output_dir_script3)) {
dir.create(output_dir_script3)
cat("Created directory:", output_dir_script3, "\n")
}
count_store <- file.path(output_dir_script3, "sampleQC_countData.RData")
cpm_store <- file.path(output_dir_script3, "sampleQC_cpmData.RData")
metadata_store <- file.path(output_dir_script3, "sampleQC_metaData.RData")
count_threshold <- 600000 # Minimum library size
corr_threshold <- 0.9     # Minimum replicate correlation
# Load packages
library(tidyverse)
library(ggrepel) # For repelling text labels in ggplot
# Load data saved from Script 2
cpmData  <- read.csv("output/cpm_store2.csv")
countData <- read.csv("output/count_store.csv")
metadata <- load("C:/Users/hala2/Universiteit Leiden/BOO 2025 - BOO CDS Giulia team - BOO CDS Giulia team/Students/Hala/Project/Hala-BOO/output/metaData.Rdata")
countData <- countData %>% column_to_rownames(var = "X")
#1. Get sample identifiers from the column names of countData.
countData_sample_colnames <- colnames(countData)
# 2. Get sample identifiers from the 'sample_ID' column of metaData.
metaData_sample_ids <- metaData$sample_ID
are_identical_and_in_order <- all(countData_sample_colnames == metaData_sample_ids)
print (are_identical_and_in_order)
# Yes, there are identical
# Calculate new library sizes from the current (probe-QC'd) countData
recalculated_library_sizes <- colSums(countData)
#Create a data frame from these new library sizes for merging.
new_lib_size_df <- data.frame(
sample_ID = names(recalculated_library_sizes),
lib_size_recalculated = recalculated_library_sizes,
row.names = NULL # Ensure default row names for this temporary df
)
# 3. Merge the new library sizes into 'metaData'.
if ("lib_size" %in% colnames(metaData)) {
metaData <- metaData %>% select(-lib_size)
cat("Removed existing 'lib_size' column from 'metaData'.\n")
}
metaData <- metaData %>%
select(-any_of(c("lib_size_recalculated", "lib_size.x", "lib_size.y")))
metaData <- metaData %>%
left_join(new_lib_size_df, by = "sample_ID") %>%
rename(lib_size = lib_size_recalculated)
print(head(metaData %>% select(sample_ID, lib_size, any_of(c("low_reads_flag", "low_corr_flag")))))
#lib_size: This column now contains the newly recalculated library sizes. These values were derived by summing up all the counts for each sample in your current countData object
print(summary(metaData$lib_size))
lib_size_histogram <- ggplot(metaData, aes(x = lib_size)) +
geom_histogram(
binwidth = 200000,
fill = "steelblue",
color = "black",
alpha = 0.7
) +
scale_x_continuous(
labels = scales::comma,
n.breaks = 8
) +
scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
labs(
title = "Distribution of Sample Library Sizes (after Probe QC)",
x = "Library Size (Total Counts per Sample)",
y = "Number of Samples (Frequency)"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold")
)
print(lib_size_histogram)
#The distribution appears roughly unimodal, with the main peak centered around 3.5 to 4.0 million reads. This aligns well with your calculated median (~3.66M) and mean (~3.64M).
#Based on mu summary statistics, the library sizes range from a minimum of 1,255,337 to a maximum of 5,244,421. The histogram visually confirms this spread, with bars covering this range.
#Yes, this range and distribution are generally reasonable and look quite good for a TempO-Seq experiment.Sufficient Depth, Above Minimum Thresholds and No Extreme Outliers.
# 1. Create the 'low_reads_flag' in metaData.
if ("low_reads_flag" %in% colnames(metaData)) {
metaData <- metaData %>% select(-low_reads_flag)
}
metaData <- metaData %>%
select(-any_of(c("low_reads_flag.x", "low_reads_flag.y")))
metaData <- metaData %>%
mutate(
low_reads_flag = ifelse(lib_size < count_threshold, TRUE, FALSE)
)
# 2. Display a summary of the new flag.
print(table(metaData$low_reads_flag, useNA = "ifany"))
#This output means that all 60 samples in your metaData have a low_reads_flag of FALSE. Therefore, no samples were flagged as having low reads because all of them had a library size greater than or equal to the 600,000 count threshold.
plot_data_boxplot <- metaData %>%
mutate(
conc_factor = factor(conc_amt), # Treat concentration as a categorical variable for fill
low_reads_flag = factor(low_reads_flag, levels = c(TRUE, FALSE), labels = c("Low Reads", "OK Reads"))
)
cat("Prepared 'plot_data_boxplot' for plotting.\n")
cat("Summary of 'low_reads_flag' factor levels in plot_data_boxplot:\n")
print(table(plot_data_boxplot$low_reads_flag, useNA = "ifany"))
cat("\n")
# Create the boxplot
lib_size_boxplot <- ggplot(plot_data_boxplot, aes(x = compound_name, y = lib_size)) +
geom_boxplot(
aes(fill = conc_factor),
outlier.shape = NA, # We'll use jitter to show all points, so hide default boxplot outliers
alpha = 0.7,        # Transparency for the box fill
notch = FALSE       # Optional: set to TRUE for notched boxplots
) +
geom_jitter(
aes(color = low_reads_flag),
width = 0.25,       # Amount of horizontal jitter
alpha = 0.8,        # Transparency of points
size = 2            # Size of points
) +
geom_hline(
yintercept = count_threshold,
linetype = "dashed",
color = "red",
linewidth = 1
) +
annotate(
"text",
x = Inf, # Position to the far right
y = count_threshold,
label = paste("Threshold =", scales::comma(count_threshold)),
hjust = 1.05, # Adjust to be just right of the plot edge
vjust = -0.5, # Adjust to be slightly above the line
color = "red",
size = 3.5
) +
scale_y_continuous(labels = scales::comma) + # Format y-axis with commas
scale_fill_viridis_d(option = "D", name = "Concentration Amount") + # Colorblind-friendly discrete palette for fill
scale_color_manual(
name = "Library Size Status",
values = c("Low Reads" = "orange", "OK Reads" = "black"), # Colors for jitter points
drop = FALSE # Ensures all legend items appear even if no data for one
) +
labs(
title = "Library Size Distribution by Compound",
subtitle = "Points show individual samples, colored by library size status relative to threshold.",
x = "Compound Name",
y = "Library Size (Total Counts per Sample)"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
plot.subtitle = element_text(hjust = 0.5, size = 10),
axis.text.x = element_text(angle = 45, hjust = 1, size = 10), # Angle x-axis labels
legend.position = "top"
)
print(lib_size_boxplot)
# Controls (DMSO, Medium): Show consistent and high library sizes, indicating good quality.
#Diisopropanolamine: Library sizes are fairly consistent across its different concentrations.
#L-Tyrosine: Shows more variability in library sizes across its concentrations compared to other groups.
#Overall: No obvious trend of library size changing systematically with drug concentration is visible. The data generally indicates robust sequencing depth across all samples.
#Calculate log2(CPM + 1)
logcpmData <- log2(cpmData + 1)
logcpmData
cpmData
#Calculate log2(CPM + 1)
cpmData <- cpmData %>% column_to_rownames(var = "X")
logcpmData <- log2(cpmData + 1)
logcpmData
# clean
rm(list = ls())
count_path <- file.path("output/count_store.csv")
cpm_path <- file.path("output/cpm_store2.csv")
metadata_path <- file.path("output/processed_metaData.RData")
output_dir_script3 <- "output"
if (!dir.exists(output_dir_script3)) {
dir.create(output_dir_script3)
cat("Created directory:", output_dir_script3, "\n")
}
count_store <- file.path(output_dir_script3, "sampleQC_countData.RData")
cpm_store <- file.path(output_dir_script3, "sampleQC_cpmData.RData")
metadata_store <- file.path(output_dir_script3, "sampleQC_metaData.RData")
count_threshold <- 600000 # Minimum library size
corr_threshold <- 0.9     # Minimum replicate correlation
# Load packages
library(tidyverse)
library(ggrepel) # For repelling text labels in ggplot
# Load data saved from Script 2
cpmData  <- read.csv("output/cpm_store2.csv")
countData <- read.csv("output/count_store.csv")
metadata <- load("C:/Users/hala2/Universiteit Leiden/BOO 2025 - BOO CDS Giulia team - BOO CDS Giulia team/Students/Hala/Project/Hala-BOO/output/metaData.Rdata")
countData <- countData %>% column_to_rownames(var = "X")
#1. Get sample identifiers from the column names of countData.
countData_sample_colnames <- colnames(countData)
# 2. Get sample identifiers from the 'sample_ID' column of metaData.
metaData_sample_ids <- metaData$sample_ID
are_identical_and_in_order <- all(countData_sample_colnames == metaData_sample_ids)
print (are_identical_and_in_order)
# Yes, there are identical
# Calculate new library sizes from the current (probe-QC'd) countData
recalculated_library_sizes <- colSums(countData)
#Create a data frame from these new library sizes for merging.
new_lib_size_df <- data.frame(
sample_ID = names(recalculated_library_sizes),
lib_size_recalculated = recalculated_library_sizes,
row.names = NULL # Ensure default row names for this temporary df
)
# 3. Merge the new library sizes into 'metaData'.
if ("lib_size" %in% colnames(metaData)) {
metaData <- metaData %>% select(-lib_size)
cat("Removed existing 'lib_size' column from 'metaData'.\n")
}
metaData <- metaData %>%
select(-any_of(c("lib_size_recalculated", "lib_size.x", "lib_size.y")))
metaData <- metaData %>%
left_join(new_lib_size_df, by = "sample_ID") %>%
rename(lib_size = lib_size_recalculated)
print(head(metaData %>% select(sample_ID, lib_size, any_of(c("low_reads_flag", "low_corr_flag")))))
#lib_size: This column now contains the newly recalculated library sizes. These values were derived by summing up all the counts for each sample in your current countData object
print(summary(metaData$lib_size))
lib_size_histogram <- ggplot(metaData, aes(x = lib_size)) +
geom_histogram(
binwidth = 200000,
fill = "steelblue",
color = "black",
alpha = 0.7
) +
scale_x_continuous(
labels = scales::comma,
n.breaks = 8
) +
scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
labs(
title = "Distribution of Sample Library Sizes (after Probe QC)",
x = "Library Size (Total Counts per Sample)",
y = "Number of Samples (Frequency)"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold")
)
print(lib_size_histogram)
#The distribution appears roughly unimodal, with the main peak centered around 3.5 to 4.0 million reads. This aligns well with your calculated median (~3.66M) and mean (~3.64M).
#Based on mu summary statistics, the library sizes range from a minimum of 1,255,337 to a maximum of 5,244,421. The histogram visually confirms this spread, with bars covering this range.
#Yes, this range and distribution are generally reasonable and look quite good for a TempO-Seq experiment.Sufficient Depth, Above Minimum Thresholds and No Extreme Outliers.
# 1. Create the 'low_reads_flag' in metaData.
if ("low_reads_flag" %in% colnames(metaData)) {
metaData <- metaData %>% select(-low_reads_flag)
}
metaData <- metaData %>%
select(-any_of(c("low_reads_flag.x", "low_reads_flag.y")))
metaData <- metaData %>%
mutate(
low_reads_flag = ifelse(lib_size < count_threshold, TRUE, FALSE)
)
# 2. Display a summary of the new flag.
print(table(metaData$low_reads_flag, useNA = "ifany"))
#This output means that all 60 samples in your metaData have a low_reads_flag of FALSE. Therefore, no samples were flagged as having low reads because all of them had a library size greater than or equal to the 600,000 count threshold.
plot_data_boxplot <- metaData %>%
mutate(
conc_factor = factor(conc_amt), # Treat concentration as a categorical variable for fill
low_reads_flag = factor(low_reads_flag, levels = c(TRUE, FALSE), labels = c("Low Reads", "OK Reads"))
)
cat("Prepared 'plot_data_boxplot' for plotting.\n")
cat("Summary of 'low_reads_flag' factor levels in plot_data_boxplot:\n")
print(table(plot_data_boxplot$low_reads_flag, useNA = "ifany"))
cat("\n")
# Create the boxplot
lib_size_boxplot <- ggplot(plot_data_boxplot, aes(x = compound_name, y = lib_size)) +
geom_boxplot(
aes(fill = conc_factor),
outlier.shape = NA, # We'll use jitter to show all points, so hide default boxplot outliers
alpha = 0.7,        # Transparency for the box fill
notch = FALSE       # Optional: set to TRUE for notched boxplots
) +
geom_jitter(
aes(color = low_reads_flag),
width = 0.25,       # Amount of horizontal jitter
alpha = 0.8,        # Transparency of points
size = 2            # Size of points
) +
geom_hline(
yintercept = count_threshold,
linetype = "dashed",
color = "red",
linewidth = 1
) +
annotate(
"text",
x = Inf, # Position to the far right
y = count_threshold,
label = paste("Threshold =", scales::comma(count_threshold)),
hjust = 1.05, # Adjust to be just right of the plot edge
vjust = -0.5, # Adjust to be slightly above the line
color = "red",
size = 3.5
) +
scale_y_continuous(labels = scales::comma) + # Format y-axis with commas
scale_fill_viridis_d(option = "D", name = "Concentration Amount") + # Colorblind-friendly discrete palette for fill
scale_color_manual(
name = "Library Size Status",
values = c("Low Reads" = "orange", "OK Reads" = "black"), # Colors for jitter points
drop = FALSE # Ensures all legend items appear even if no data for one
) +
labs(
title = "Library Size Distribution by Compound",
subtitle = "Points show individual samples, colored by library size status relative to threshold.",
x = "Compound Name",
y = "Library Size (Total Counts per Sample)"
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
plot.subtitle = element_text(hjust = 0.5, size = 10),
axis.text.x = element_text(angle = 45, hjust = 1, size = 10), # Angle x-axis labels
legend.position = "top"
)
print(lib_size_boxplot)
# Controls (DMSO, Medium): Show consistent and high library sizes, indicating good quality.
#Diisopropanolamine: Library sizes are fairly consistent across its different concentrations.
#L-Tyrosine: Shows more variability in library sizes across its concentrations compared to other groups.
#Overall: No obvious trend of library size changing systematically with drug concentration is visible. The data generally indicates robust sequencing depth across all samples.
#Calculate log2(CPM + 1)
cpmData <- cpmData %>% column_to_rownames(var = "X")
logcpmData <- log2(cpmData + 1)
# Display the head of the new logcpmData object.
replicateFilterOutput <- data.frame()
# For each mean ID (experimental condition)
for(i in unique(metaData$mean_ID)){
# Subset the meta data to keep only samples from this experiment
metaDataReps <- metaData %>%
filter(mean_ID == i)
# Subset the log2 CPM values to keep only these samples
cpmDataReps <- logcpmData[, metaDataReps$sample_ID]
# Loop through each column in the CPM data
for(j in 1:ncol(cpmDataReps)){
# In a pairwise fashion
for(k in 1:ncol(cpmDataReps)){
# Save the position in the loops that you are in
sample_A <- colnames(cpmDataReps)[j]
sample_B <- colnames(cpmDataReps)[k]
# Don't calculate pairwise correlations between identical samples (since it will be 1)
if(sample_A != sample_B){
# Calculate pairwise correlation values
r2 <- cor(cpmDataReps[,j], cpmDataReps[,k])
# Update the filter output data frame
replicateFilterOutput <- rbind(
replicateFilterOutput,
data.frame(mean_ID = i,
sample_A = sample_A,
sample_B = sample_B,
r2 = r2))
}
}
}
}
head(replicateFilterOutput)
replicateFilterOutput <- replicateFilterOutput %>%
# Separate sample name into compound and concentration using the underscore
separate(sample_A,
into = c("Compound", "Conc_ID", NA, NA),
remove = F,
sep = "_") %>%
# If the compound is DMSO then keep only the first 5 letters (else we get DMSOHigh1 and DMSOHigh2 :D)
mutate(Compound = ifelse(grepl("DMSO", Compound), substr(Compound,1,5), Compound)) %>%
# Group by sample
group_by(sample_A) %>%
# Save the maximum pairwise correlation for that sample
mutate(max_r2 = max(r2, na.rm = T)) %>%
ungroup()
# Inspect output
summary(replicateFilterOutput$max_r2)
#max_r2 (<dbl> for double/numeric):
#This column shows the maximum Pearson correlation coefficient (r) that a given sample achieved when compared pairwise against all other replicates within its specific experimental group
#Values close to 1 indicate very high correlation
#The output you're seeing shows that the first 6 samples listed all have very high max_r2 values (all > 0.98), which is excellent and suggests these replicates are highly similar to at least one other replicate in their respective groups.
replicateFilterOutput %>%
# Plot the sample ID against the pairwise correlation
ggplot(aes(x = sample_A, y = r2)) +
# Draw a boxplot of the pairwise correlation distribution
geom_boxplot(color = "grey80") +
# With points for the actual values
geom_point(color = "grey60", size = 0.5) +
# Highlight the maximum pairwise correlation for each sample
geom_point(aes(y = max_r2, color = Conc_ID),
size = 1.5) +
# Draw a line for the filter threshold
geom_hline(aes(yintercept = corr_threshold),
color = "red", linetype = "dashed") +
ylab("") + xlab("Sample ID") + ggtitle("Replicate correlations") +
theme_bw() +
# Do not print sample names
theme(axis.text.x = element_blank()) +
# Make a different plot for each compound, allowing the x-axis to change for different samples
facet_wrap(~Compound, scales='free_x', nrow=2)
#The boxplot shows that replicate correlations (max_r2) are very high across almost all samples and conditions, with most values well above the 0.9 threshold (red dashed line). This indicates good reproducibility.
#Controls (DMSOHigh_P1, DMSOLow_P1, Medium_P6) show tight, consistently high correlations.
#Treatments (Diisopropanolamine and L-Tyrosine conditions) also show very good correlations, generally comparable to controls, with low variability within most groups.
# Make a data frame of sample IDs and max r2
replicateFilterMerge <- replicateFilterOutput %>%
select(sample_ID = sample_A, max_r2) %>%
distinct()
# Merge with meta data
metaData <- left_join(metaData, replicateFilterMerge,
by = "sample_ID") %>%
mutate(flagLowCorr = ifelse(max_r2 <= corr_threshold, T, F))
table(metaData$flagLowCorr)
# This output indicates that all 60 samples in your dataset have a low_corr_flag of FALSE. This means that no samples were flagged as having a low replicate correlation based on your criterion (max_r2 < corr_threshold, where corr_threshold is 0.9).
#This aligns with the visual interpretation of the boxplot from Exercise 13, where all samples appeared to have max_r2 values at or above the 0.9 threshold. It's a good sign, suggesting strong reproducibility among your replicates.
# Inspect the flagged samples
metaData %>%
filter(flagLowCorr)
#ther is none
#
#
# Subset the metadata to keep only high quality samples
metaData_qc <- metaData %>%
filter(!low_reads_flag & !flagLowCorr)
# Subset the count and CPM data
cpmData_qc <- cpmData[ , metaData$sample_ID]
countData_qc <- countData[ , metaData$sample_ID]
# Check dimensions
dim(metaData_qc)
# 60 32
dim(countData_qc)
# 22533    60
dim(cpmData_qc)
# 13124    60
write.csv(countData_qc,"output/count_store.csv")
write.csv(metaData_qc,"output/metadata_store.csv")
write.csv(cpmData_qc,"output/cpm_store.csv")
library(sessioninfo)
session_info()
# Clean
rm(list=ls())
# Paths
low_store <- file.path("Output/low_store.csv")
high_store <- file.path("Output/high_store.csv")
txg_store <- "TXG_upload"
# Load packages
library(tidyverse)
res_low  <- read_csv("output/low_store.csv")
res_high  <- read_csv("output/high_store.csv")
txg_high <- res_high %>%
separate(mean_ID, sep="_", into=c("Compound", "conc", NA), remove=F) %>%
mutate(time = 24) %>%
select(
experiment = Compound,
gene_id = gene_symbol,
time, conc, log2fc = log2FoldChange, pvalue, padj)
write_tsv(txg_high,"output/uploadfile1_txg_high.txt")
txg_low <- res_low %>%
separate(mean_ID, sep="_", into=c("Compound", "conc", NA), remove=F) %>%
mutate(time = 24) %>%
select(
experiment = Compound,
gene_id = gene_symbol,
time, conc, log2fc = log2FoldChange, pvalue, padj)
write_tsv(txg_low,"output/uploadfile2_txg_low.txt")
devtools::session_info()
library(tidyverse)
library(ComplexHeatmap)
# Subset metadata to include only these columns
heatmap_df <- txg_low %>%
select(any_of(plot_vars))
library(tidyverse)
library(ComplexHeatmap)
# Subset metadata to include only these columns
heatmap_df <- txg_low %>%
select(any_of(plot_vars))
